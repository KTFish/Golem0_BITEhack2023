{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"2017_2019.csv\")\n",
    "df.drop(['Unnamed: 18'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = set()\n",
    "for i,data in df.iterrows():\n",
    "    dates.add(pd.to_datetime( \n",
    "                             str(data['Year'])[:-2]+'-'+str(data['Month'])[:-2] + '-' + str(data['Day'])[:-2],\n",
    "                             format=\"%Y-%m-%d\"\n",
    "                             ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day(df:pd.DataFrame,day:pd.Timestamp) -> pd.DataFrame:\n",
    "    \n",
    "    return df.loc[ (df ['Year'] == day.year) & \n",
    "                  (df['Day'] == day.day) &\n",
    "                  (df['Month'] == day.month)]\n",
    "    \n",
    "def get_records_night(df:pd.DataFrame,day:pd.Timestamp):\n",
    "    records_beafore_df = get_n_days_beafore(df,day,1)\n",
    "    records_beafore_df = records_beafore_df.loc[(records_beafore_df.Hour > 12)  & (records_beafore_df[\"Clearsky DNI\"] != 0)]\n",
    "    \n",
    "    records_df = get_day(df,day)\n",
    "    records_df = records_df.loc[(records_df.Hour < 12) &( records_df.DNI == 0) &(records_df[\"Clearsky DNI\"] != 0)]\n",
    "    \n",
    "    return(pd.concat([records_beafore_df,records_df]))\n",
    "    \n",
    "    \n",
    "  \n",
    "def get_n_days_beafore(df:pd.DataFrame,day:pd.Timestamp,n:int):\n",
    "    day_beafore = day - pd.offsets.Day(n)\n",
    "    return get_day(df,day_beafore)\n",
    "\n",
    "def get_working_day(df:pd.DataFrame,day:pd.Timestamp):\n",
    "    records = get_day(df,day)\n",
    "    return records.loc[(records.DNI != 0) | (records[\"Clearsky DNI\"] != 0)]\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pd.Series( list(dates)).sort_values()\n",
    "get_records_night(df,_.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_df =pd.DataFrame()\n",
    "for idx,date in enumerate( pd.Series( list(dates)).sort_values().values):\n",
    "    \n",
    "    date = pd.to_datetime(date)\n",
    "    day = get_working_day(df,date)\n",
    "    record = pd.DataFrame([{'date':date}])\n",
    "    \n",
    "    record['month'] = date.month\n",
    "    record['len_day'] = len(day)\n",
    "    record['temp_mean'] = day.Temperature.mean()\n",
    "    record['press_mean'] = day.Pressure.mean()\n",
    "    record['wind_mean'] = day[\"Wind Speed\"].mean()\n",
    "    \n",
    "    \n",
    "    night = get_records_night(df,date)\n",
    "    \n",
    "    if idx == 0:\n",
    "        record['len_night'] = 0\n",
    "    else:\n",
    "        record['len_night'] = len(night)\n",
    "        record['night_temp_mean'] = night.Temperature.mean()\n",
    "        record['night_press_mean'] = night.Pressure.mean()\n",
    "        record['night_wind_mean'] = night[\"Wind Speed\"].mean()\n",
    "    \n",
    "    record['Y'] = (day[\"Clearsky DNI\"].sum() + day['DNI'].sum()) / record['len_day']\n",
    "    records_df = pd.concat([records_df,record])\n",
    "records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_df[records_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_df.dropna(inplace=True)\n",
    "records_df.drop([\"date\"], inplace= True,axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Data_n_records(df, num, flatten_x=False):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(len(df)):\n",
    "        if i < num + 1:\n",
    "            pass\n",
    "        else:\n",
    "            X.append(df.iloc[i-num-1:i-1].values)\n",
    "            Y.append(df.iloc[i].Y)\n",
    "    \n",
    "    if flatten_x:  # Option to return one long row containing the X data\n",
    "        X = np.array(X)\n",
    "        first, second, third = X.shape\n",
    "        return  X.reshape(first, second * third), np.array(Y)\n",
    "\n",
    "    \n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "X,Y = get_Data_n_records(records_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTED_RECORD = 1\n",
    "\n",
    "X, _ = get_Data_n_records(records_df, TESTED_RECORD)\n",
    "X = np.array(X)\n",
    "first, second, third = X.shape\n",
    "X = X.reshape(first, second * third)\n",
    "\n",
    "X_flattened, _ = get_Data_n_records(records_df, TESTED_RECORD, flatten_x=True)\n",
    "assert X.shape == X_flattened.shape\n",
    "\n",
    "for i in range(len(X)):\n",
    "    if sum([X[i, x] != X_flattened[i, x] for x in range(X.shape[1])]) >= 1:\n",
    "        control = [X[i, x] != X_flattened[i, x] for x in range(X.shape[1])]\n",
    "assert (X == X_flattened).all()\n",
    "\n",
    "\n",
    "assert pd.Series(X_flattened[1]).sum() == pd.Series(X[1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = pd.DataFrame(X_flattened)#[:, control])\n",
    "f1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = pd.DataFrame(X)\n",
    "f2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.heatmap(f2 == f1)\n",
    "# (f2 == f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np \n",
    "# import keras as kr\n",
    "# import sklearn as skl\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_Data_n_records(records_df,3, flatten_x=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "# regr = RandomForestRegressor(random_state=0)\n",
    "# regr.fit(x_train, y_train)\n",
    "\n",
    "# mlp_model = kr.Sequential([\n",
    "#     kr.layers.Flatten(input_shape = (3,10)),\n",
    "#     kr.layers.Dense(128, activation = 'relu'),\n",
    "#     kr.layers.BatchNormalization(),\n",
    "#     kr.layers.Dropout(0.1),\n",
    "#     kr.layers.Dense(64, activation='relu'),\n",
    "#     kr.layers.BatchNormalization(),\n",
    "#     kr.layers.Dropout(0.1),\n",
    "#     kr.layers.Dense(1, activation = 'sigmoid')\n",
    "# ])\n",
    "\n",
    "# mlp_model.compile()\n",
    "# history = mlp_model.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_estimators =[4]#  [4, 20, 100, 500, 2000] # Number of trees in the forest\n",
    "max_depth = [2]# [ 7, 15] # Maximum number of levels in the tree\n",
    "max_features = ['sqrt', 'auto'] # Number of features to consider at every split\n",
    "min_samples_split = [2]#, 3, 5, 7] # Minimum number of samples required to split a node\n",
    "min_samples_leaf = [2]#, 3] # Minimum number of samples required at each leaf node\n",
    "bootstrap = [True, False] # Method of selecting samples for training each tree\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "forest = RandomForestRegressor(random_state=0)\n",
    "forest_grid = GridSearchCV(estimator=forest,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=3, verbose=2, n_jobs=-1,error_score=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aad7386399a7c27607516c50e72e17040ab97cac8def3ed7dd10a0a9a87ff1df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
